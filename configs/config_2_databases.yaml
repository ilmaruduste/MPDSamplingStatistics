DATABASE CONNECTION:
  DB HOST: 'localhost'
  DB NAME: 'dummy_database'
  DB USERNAME: 'dummy_user'
  DB PASSWORD: 'dummy_password'
  DB PORT: '5432'

DATABASE CONNECTION2:
  DB HOST: 'localhost'
  DB NAME: 'dummy_other_database'
  DB USERNAME: 'dummy_other_user'
  DB PASSWORD: 'dummy_other_password'
  DB PORT: '5432'

INPUT DATA:
  DATA SCHEMAS: ['du_dummy_results', 'du_dummy_results']  # The first schema here is the one the other schemas are compared to. NB! There should be as many Data Schemas as corresponding types!
  CORRESPONDING TYPES: ['100% data', '5% data']                   # Type of sample/compression on data. E.g. '5% data' or '100% PIPE1 data'
  TABLE NAMES: ['dummy_results_table', 'dummy_results_table_2']   # The names of the tables to be analyzed
  INDICATORS: ['unique_visitor_cnt', 'trip_present_cnt']          # Indicators in the tables to analyze
  DATA SOURCE: 'DomesticInbound'                                  # Options 'DomesticInbound' and 'Outbound'
  JOIN CATEGORIES: ['lau_id', 'lau_level','period']               # The combinations that make up a unique row in a table. These fields are used to join values from one table to another.
  FILTER NAME: 'lau_level'            # If this has a value, then an extra grouping is made into the output file and FILTER VALUES are looped through with the group
  FILTER VALUES: [1,2]                # These values are used for grouping the analysis.
  COEF VALUES: [1,20]                 # All indicators in tables get multiplied by the coef (coefs here correspond to data schemas and therefore data types)

OUTPUT DATA:
  FOLDER: './output'                      # The path of the output file folder
  FILENAME: 'dummy_results_analysed.csv'  # The filename of the output. NB! A timestamp is automatically added as a prefix to the filename.
  TYPE: ['long']                          # Long or wide or both